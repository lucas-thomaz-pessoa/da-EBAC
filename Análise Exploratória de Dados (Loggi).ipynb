{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKsnU45GDtlWEFhUTTjn7g"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Análise Exploratória de Dados (Loggi)**"
      ],
      "metadata": {
        "id": "RHq5DwoSu5HN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1\\. Contexto\n",
        "Esse Projeto faz parte da formação \"Analista de Dados\" da EBAC e foi realizado em parceria com a empresa Loggi. Comessaremos com os dados de entrega, fornecidos pela empresa, referentes a cidade de brasília, em formato JSON. Iremos estruturar esses dados em um formato tabular, manipular-los, enrriquecer-los para, a partir deles, gerar visualisações e insigths."
      ],
      "metadata": {
        "id": "mdFOpS4YvGEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install geopandas"
      ],
      "metadata": {
        "id": "HdrZsQDsxP_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQWWXrzvt0N5"
      },
      "outputs": [],
      "source": [
        "# Importações\n",
        "\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas\n",
        "import geopy\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.extra.rate_limiter import RateLimiter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dos dados brutos em formato JSON\n",
        "\n",
        "!wget -q \"https://raw.githubusercontent.com/andre-marcos-perez/ebac-course-utils/main/dataset/deliveries.json\" -O deliveries.json"
      ],
      "metadata": {
        "id": "KGA-sfAJViMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dos dados de localização convertidos de coordenadas para endereços (entrega por entrega)\n",
        "\n",
        "!wget -q \"https://raw.githubusercontent.com/andre-marcos-perez/ebac-course-utils/main/dataset/deliveries-geodata.csv\" -O deliveries-geodata.csv"
      ],
      "metadata": {
        "id": "xpmzWQgtWBZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download do mapa do distrito federal através do site oficial do IBGE\n",
        "\n",
        "!wget -q \"https://geoftp.ibge.gov.br/cartas_e_mapas/bases_cartograficas_continuas/bc100/go_df/versao2016/shapefile/bc100_go_df_shp.zip\" -O distrito-federal.zip\n",
        "!unzip -q distrito-federal.zip -d ./maps\n",
        "!cp ./maps/LIM_Unidade_Federacao_A.shp ./distrito-federal.shp\n",
        "!cp ./maps/LIM_Unidade_Federacao_A.shx ./distrito-federal.shx"
      ],
      "metadata": {
        "id": "FJOuE0cdWXWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estruturando o dado JSON em um formato tabular\n",
        "\n",
        "with open('deliveries.json', mode='r', encoding='utf8') as file:\n",
        "  data = json.load(file)\n",
        "\n",
        "deliveries_df = pd.DataFrame(data)\n",
        "origin_df = pd.json_normalize(deliveries_df[\"origin\"])\n",
        "\n",
        "deliveries_df = pd.merge(left=deliveries_df, right=origin_df, how='inner', left_index=True, right_index=True)\n",
        "deliveries_df = deliveries_df.drop(\"origin\", axis=1)\n",
        "deliveries_df = deliveries_df[[\"name\", \"region\", \"lng\", \"lat\", \"vehicle_capacity\", \"deliveries\"]]\n",
        "deliveries_df.rename(columns={\"lng\": \"origin_lng\", \"lat\": \"origin_lat\"}, inplace=True)\n",
        "\n",
        "deliveries_exploded_df = deliveries_df[[\"deliveries\"]].explode(\"deliveries\")\n",
        "deliveries_normalized_df = pd.concat([\n",
        "  pd.DataFrame(deliveries_exploded_df[\"deliveries\"].apply(lambda record: record[\"size\"])).rename(columns={\"deliveries\": \"delivery_size\"}),\n",
        "  pd.DataFrame(deliveries_exploded_df[\"deliveries\"].apply(lambda record: record[\"point\"][\"lng\"])).rename(columns={\"deliveries\": \"delivery_lng\"}),\n",
        "  pd.DataFrame(deliveries_exploded_df[\"deliveries\"].apply(lambda record: record[\"point\"][\"lat\"])).rename(columns={\"deliveries\": \"delivery_lat\"}),\n",
        "  ], axis= 1)\n",
        "\n",
        "deliveries_df = deliveries_df.drop(\"deliveries\", axis=1)\n",
        "deliveries_df = pd.merge(left=deliveries_df, right=deliveries_normalized_df, how='right', left_index=True, right_index=True)\n",
        "deliveries_df.reset_index(inplace=True, drop=True)"
      ],
      "metadata": {
        "id": "uTuBFESsXNoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deliveries_df.head()"
      ],
      "metadata": {
        "id": "i-iCo6qoZ3dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazendo a geocodificação reversa dos HUBS de distribuição\n",
        "\n",
        "hubs = deliveries_df[[\"region\", \"origin_lng\", \"origin_lat\"]]\n",
        "hubs = hubs.drop_duplicates().sort_values(by=\"region\").reset_index(drop=True)\n",
        "\n",
        "geolocator = Nominatim(user_agent=\"ebac_geocoder\")\n",
        "location = geolocator.reverse(\"-15.657013854445248, -47.802664728268745\")\n",
        "geocoder = RateLimiter(geolocator.reverse, min_delay_seconds=1)\n",
        "\n",
        "hubs[\"coordinates\"] = hubs[\"origin_lat\"].astype(str)  + \", \" + hubs[\"origin_lng\"].astype(str)\n",
        "hubs[\"geodata\"] = hubs[\"coordinates\"].apply(geocoder)\n",
        "\n",
        "hubs.head()"
      ],
      "metadata": {
        "id": "DHlTnYAvaEXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aprimorando o Data Frame de entrgas\n",
        "\n",
        "hub_geodata_df = pd.json_normalize(hubs[\"geodata\"].apply(lambda data: data.raw))\n",
        "hub_geodata_df = hub_geodata_df[[\"address.town\", \"address.suburb\", \"address.city\"]]\n",
        "hub_geodata_df.rename(columns={\"address.town\": \"hub_town\", \"address.suburb\": \"hub_suburb\", \"address.city\": \"hub_city\"}, inplace=True)\n",
        "hub_geodata_df[\"hub_city\"] = np.where(hub_geodata_df[\"hub_city\"].notna(), hub_geodata_df[\"hub_city\"], hub_geodata_df[\"hub_town\"])\n",
        "hub_geodata_df[\"hub_suburb\"] = np.where(hub_geodata_df[\"hub_suburb\"].notna(), hub_geodata_df[\"hub_suburb\"], hub_geodata_df[\"hub_city\"])\n",
        "hub_geodata_df = hub_geodata_df.drop(\"hub_town\", axis=1)\n",
        "hubs = pd.merge(left=hubs, right=hub_geodata_df, left_index=True, right_index=True)\n",
        "hubs = hubs[[\"region\", \"hub_suburb\", \"hub_city\"]]\n",
        "\n",
        "deliveries_df = pd.merge(left=deliveries_df, right=hubs, how=\"inner\", on=\"region\")\n",
        "deliveries_df = deliveries_df[[\"name\", \"region\", \"origin_lng\", \"origin_lat\", \"hub_city\", \"hub_suburb\", \"vehicle_capacity\", \"delivery_size\", \"delivery_lng\", \"delivery_lat\"]]\n",
        "deliveries_df.head()"
      ],
      "metadata": {
        "id": "cs-qKmBjhuyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uma vez que há mais de seicentas mil consultas a serem feitas a respeito do local da entrega, seria inviável converter pelo código.\n",
        "# Por isso será um arquivo csv com as coordenadas previamente convertidas para endereços.\n",
        "\n",
        "deliveries_geodata_df = pd.read_csv('deliveries-geodata.csv')\n",
        "deliveries_geodata_df.head(n=6)"
      ],
      "metadata": {
        "id": "BJAEM40YiTz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deliveries_df = pd.merge(left=deliveries_df, right=deliveries_geodata_df[['delivery_city', 'delivery_suburb']],\n",
        "                         how='inner', left_index=True, right_index=True)\n",
        "deliveries_df.head(n=7)"
      ],
      "metadata": {
        "id": "mNyolgqKkbi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2\\. Verificando a qualidade dos dados\n",
        "Uma vez que os dados já foram tratados e enrriquecidos, nos resta verificar a consistência do schema e a presença de valores faltantes. Dessa forma será possível dimensionar a qualidade dos dados obtidos.\n"
      ],
      "metadata": {
        "id": "EulH3CzYoUuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Observe que o Data Frame criamos possui as dimenções e tipo de dado esperado em cada coluna\n",
        "deliveries_df.info()"
      ],
      "metadata": {
        "id": "QBl9lr89pTUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Como foi verificado no código anterior, possuímos valores faltantes em duas colunas.\n",
        "# Também podemos verificar isso com o seguint3e comando.\n",
        "deliveries_df.isna().any()"
      ],
      "metadata": {
        "id": "_ZWMtrwopyA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifica-se que são os valores obtidos com a geocodificação reversa das entregas\n",
        "# Vamos agora dimensionar o problema.\n",
        "\n",
        "100 * (deliveries_df['delivery_city'].isna().sum() / len(deliveries_df))"
      ],
      "metadata": {
        "id": "H_e-uNyhqRxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "100 * (deliveries_df['delivery_suburb'].isna().sum() / len(deliveries_df))"
      ],
      "metadata": {
        "id": "exh2fKNcrVV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analisando os valores que mais se repetem e o seu percentual em relação ao total\n",
        "\n",
        "prop_df = deliveries_df[[\"delivery_city\"]].value_counts() / len(deliveries_df)\n",
        "prop_df.sort_values(ascending=False).head(10)"
      ],
      "metadata": {
        "id": "sr1amKVAr7xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tanto na célula de código anterior, como na atual vemos que alguns dos valores não nos interessam,\n",
        "# uma vez que contem o valor \"Brasília\" e só estamos analisando dados do DF\n",
        "\n",
        "prop_df = deliveries_df[[\"delivery_suburb\"]].value_counts() / len(deliveries_df)\n",
        "prop_df.sort_values(ascending=False).head(10)"
      ],
      "metadata": {
        "id": "VkQtxNXMsh4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3\\. Criando a visualização dos dados\n",
        "Aqui, vamos alocar marcar no mapa do distrito federal onde que é cada entrega diferenciando-os por seu hub de origem."
      ],
      "metadata": {
        "id": "rOvwyG_H2cDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mapa = geopandas.read_file('distrito-federal.shp')\n",
        "mapa = mapa.loc[[0]]\n",
        "mapa.head()"
      ],
      "metadata": {
        "id": "_0rwC_VJ3isM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Primeiramente iremos criar um data frame contendo as informações necessárias para criar um mapa com is Hubs\n",
        "\n",
        "hubs_df = deliveries_df[['region', 'origin_lng', 'origin_lat']].drop_duplicates().reset_index(drop=True)\n",
        "geo_hub_df = geopandas.GeoDataFrame(hubs_df, geometry=geopandas.points_from_xy(hubs_df['origin_lng'], hubs_df['origin_lat']))\n",
        "geo_hub_df.head()"
      ],
      "metadata": {
        "id": "AiveSeE74oBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora faremos os mesmos com as entregas\n",
        "\n",
        "geo_deliveries_df = geopandas.GeoDataFrame(deliveries_df,\n",
        "                                           geometry=geopandas.points_from_xy(deliveries_df['delivery_lng'],\n",
        "                                                                                            deliveries_df['delivery_lat']))\n",
        "geo_deliveries_df.head()"
      ],
      "metadata": {
        "id": "Uh_AWJsa-fo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando o mapa em si\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (50/2.54, 50/2.54))\n",
        "mapa.plot(ax=ax, alpha=0.4, color='lightgrey')\n",
        "\n",
        "geo_deliveries_df.query('region == \"df-0\"').plot(ax=ax, markersize=1, color='red', label='df-0')\n",
        "geo_deliveries_df.query('region == \"df-1\"').plot(ax=ax, markersize=1, color='blue', label='df-1')\n",
        "geo_deliveries_df.query('region == \"df-2\"').plot(ax=ax, markersize=1, color='seagreen', label='df-2')\n",
        "\n",
        "geo_hub_df.plot(ax=ax, markersize=30, marker='x', color='black', label='hub')\n",
        "\n",
        "plt.title('Entregas no DF por Região', fontdict={'fontsize':16})\n",
        "lgnd = plt.legend(prop={'size': 15})\n",
        "\n",
        "for handle in lgnd.legendHandles:\n",
        "  handle.set_sizes([50])"
      ],
      "metadata": {
        "id": "ckWOrsHd4b1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4\\. Storytelling"
      ],
      "metadata": {
        "id": "pxApd1PiJ3Fl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As entregas partem, em sua maioria dos Hubs df-1 e df-2, sendo muito menor a quantidade de entregas oriundas do Hub df-0. Contudo, o Hub df-0 possui um raio de entregas muito maior que os demais. Por sua vez, o Hub df-1, embora concentre o maior número de entregas, necessita cobrir um raio de entregas menor.\n",
        "Assim sendo, se a capacidade de veículos é igual para todos os hubs, seria interessante fazer uma análise se essa distribuição é eficiente em dois sentidos: O primeiro seria a quantidade de frota ociosa no hub df-0, por ter um menor fluxo de entregas; O outro sentido seria averiguar se a frota do hub df-0 passa mais tempo do que os demais hubs realizando deslocamentos, o que implicaria em um custo maior de entrega. Uma possível solução seria pensar uma frota com características diferentes para cada Hub, tendo o hub df-1 veiculos maiores, que possibilitem realizar uma viagem maior enquanto fazem entregas em múltiplos destinos, o hub df-0 veículos menores e mais econômicos que não gastem tanto tempo e combustível em viagens que visam realizar entregas isoladas. Por conseguinte, o hub df-2 teria características hibridas."
      ],
      "metadata": {
        "id": "GL1QqdkwKXFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outro fato que é digno de nota foi em relação a coleta de endereços, no qual tivemos um pequeno problema com o schema de algumas regiões. Um dos motivos que pode ter ocasionado essa divergência se deve ao fato do Distrito Federal, por força do art. 32 da CRFB não poder ser dividido em municípios. Contudo, Isso não impede que o Destrito Federal seja dividido em 33 regiões administrativa, sendo uma delas, Brasília. Nesse sentido, talvez fosse mais interessante registrar em qual região administrativa é feita a entrega para que seja possível extrair métricas mais interessantes."
      ],
      "metadata": {
        "id": "DxFzw5ahPl-k"
      }
    }
  ]
}